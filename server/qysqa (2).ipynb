{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa79a6c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Directory 'static/' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypedDict\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\fitz\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\events\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhash_change\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\events\\clipboard.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClipboardDataMixin\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Event\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClipboardEvent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClipboardEvent\u001b[39;00m(Event, ClipboardDataMixin):\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\dom.py:439\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatcher\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\dispatcher.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocketEndpoint\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebsockets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocket\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, server\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m later_await\n\u001b[0;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\frontend\\server.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m app: Any \u001b[38;5;241m=\u001b[39m Starlette(debug\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[1;32m---> 24\u001b[0m app\u001b[38;5;241m.\u001b[39mmount(config\u001b[38;5;241m.\u001b[39mSTATIC_ROUTE, StaticFiles(directory\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSTATIC_DIRECTORY), name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSTATIC_NAME)\n\u001b[0;32m     25\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(GZipMiddleware)\n\u001b[0;32m     26\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(\n\u001b[0;32m     27\u001b[0m     CORSMiddleware,\n\u001b[0;32m     28\u001b[0m     allow_origins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     allow_headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\i9-14900k-2\\anaconda3\\Lib\\site-packages\\starlette\\staticfiles.py:56\u001b[0m, in \u001b[0;36mStaticFiles.__init__\u001b[1;34m(self, directory, packages, html, check_dir, follow_symlink)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_symlink \u001b[38;5;241m=\u001b[39m follow_symlink\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_dir \u001b[38;5;129;01mand\u001b[39;00m directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(directory):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Directory 'static/' does not exist"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing_extensions import TypedDict\n",
    "import fitz  # PyMuPDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "\n",
    "# ----------- JSON schema for guard‑railed output ----------------------------\n",
    "class SummaryJson(TypedDict):\n",
    "    content: str\n",
    "    title: str\n",
    "    description: str\n",
    "    location: str\n",
    "\n",
    "\n",
    "# ----------- Helper function to get embeddings ----------------------------\n",
    "def get_embeddings(text: str, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Gets the embeddings for the provided text using OpenAI's embeddings API.\n",
    "    \"\"\"\n",
    "    response = openai.embeddings.create(\n",
    "        model=model,\n",
    "        input=[text]  # The input should be a list of texts\n",
    "    )\n",
    "    embeddings = [embedding['embedding'] for embedding in response['data']]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "# ----------- main callable --------------------------------------------------\n",
    "def pdf_to_summary_json(\n",
    "    pdf_path: str | Path, location_tag: str, model_name: str = \"gpt-4\"\n",
    ") -> SummaryJson:\n",
    "    \"\"\"\n",
    "    Extracts text from `pdf_path`, manually splits it, generates embeddings, and returns SummaryJson.\n",
    "    `location_tag` → value stored in the 'location' field.\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "\n",
    "    # 1) Load PDF and extract text using PyMuPDF (fitz)\n",
    "    doc = fitz.open(str(pdf_path))  # Open the PDF\n",
    "    full_text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)  # Load a page\n",
    "        full_text += page.get_text(\"text\")  # Extract text from page\n",
    "\n",
    "    # 2) Chunk text manually (let's use 1000 character chunks)\n",
    "    chunk_size = 1000\n",
    "    chunks = [full_text[i:i + chunk_size] for i in range(0, len(full_text), chunk_size)]\n",
    "\n",
    "    # 3) Get embeddings for each chunk\n",
    "    chunk_embeddings = [get_embeddings(chunk) for chunk in chunks]\n",
    "\n",
    "    # 4) Generate the query embedding\n",
    "    query = \"Make a test for students based on the lecture material\"\n",
    "    query_embedding = get_embeddings(query)\n",
    "\n",
    "    # 5) Calculate cosine similarity between query embedding and chunk embeddings\n",
    "    similarities = [cosine_similarity(query_embedding, chunk_embedding)[0][0] for chunk_embedding in chunk_embeddings]\n",
    "\n",
    "    # 6) Retrieve top‑k context based on similarity score\n",
    "    top_k = 6\n",
    "    top_k_indices = np.argsort(similarities)[-top_k:]\n",
    "    context = \"\\n\\n\".join(chunks[i] for i in top_k_indices)\n",
    "\n",
    "    # 7) Generate the mock test questions using GPT model\n",
    "    openai.api_key = 'YOUR_OPENAI_API_KEY'  # Set your OpenAI API key here\n",
    "    prompt = f\"\"\"\n",
    "    You are a mock quiz generator. Based on the provided lecture notes, create the following types of questions:\n",
    "    - One answer with 4 options to pick.\n",
    "    - Multiple choice with 5-6 options to pick.\n",
    "    - Matching questions.\n",
    "\n",
    "    The provided lecture content: {context}\n",
    "\n",
    "    Output the result in the following JSON format:\n",
    "    [\n",
    "      {{\n",
    "        \"title\": \"Who was the first president of the United States?\",  // One choice question\n",
    "        \"variants\": [\n",
    "          \"George Washington\",  // Option 1\n",
    "          \"Abraham Lincoln\"  // Option 2\n",
    "        ],\n",
    "        \"correctVariantIndex\": 0  // Correct answer is the first option (index 0)\n",
    "      }},\n",
    "      {{\n",
    "        \"title\": \"Which of the following countries were part of the Allied Powers in World War II?\",  // Multiple choice question\n",
    "        \"variants\": [\n",
    "          \"United States\",  // Option 1\n",
    "          \"Germany\",  // Option 2\n",
    "          \"Soviet Union\",  // Option 3\n",
    "          \"Italy\"  // Option 4\n",
    "        ],\n",
    "        \"correctVariantIndex\": [0, 2]  // Correct answers are the first (United States) and third (Soviet Union)\n",
    "      }},\n",
    "      {{\n",
    "        \"title\": \"Match the famous historical figures to their corresponding country:\",  // Matching question\n",
    "        \"variants\": [\n",
    "          \"George Washington\",  // Option 1\n",
    "          \"Albert Einstein\",  // Option 2\n",
    "          \"Winston Churchill\",  // Option 3\n",
    "          \"Mahatma Gandhi\"  // Option 4\n",
    "        ],\n",
    "        \"correctVariantIndex\": [0, 1, 2, 3],  // Correct matches for each country\n",
    "        \"matchWith\": [\n",
    "          \"United States\",  // Country for George Washington\n",
    "          \"Germany\",  // Country for Albert Einstein\n",
    "          \"United Kingdom\",  // Country for Winston Churchill\n",
    "          \"India\"  // Country for Mahatma Gandhi\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "\n",
    "    Ensure that the quiz questions are based only on the provided lecture notes or the test will fail.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    json_out = json.loads(response['choices'][0]['message']['content'])\n",
    "    return json_out\n",
    "\n",
    "\n",
    "# ------------- Call the function ---------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60769eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frontend\n",
      "  Downloading frontend-0.0.3-py3-none-any.whl.metadata (847 bytes)\n",
      "Requirement already satisfied: starlette>=0.12.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from frontend) (0.45.3)\n",
      "Requirement already satisfied: uvicorn>=0.7.1 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from frontend) (0.34.2)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from frontend) (2.2.0)\n",
      "Collecting aiofiles (from frontend)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from starlette>=0.12.0->frontend) (4.2.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from uvicorn>=0.7.1->frontend) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette>=0.12.0->frontend) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn>=0.7.1->frontend) (0.4.6)\n",
      "Downloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: aiofiles, frontend\n",
      "Successfully installed aiofiles-24.1.0 frontend-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd470ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"I'm sorry, but I cannot access or read PDF files directly. However, if you can provide the text or main points from the PDF, I would be happy to help you summarize or analyze it!\",\n",
      "  \"title\": \"PDF Content Inquiry\",\n",
      "  \"description\": \"Request for information about the contents of a PDF file.\",\n",
      "  \"location\": \"N/A\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    summary = pdf_to_summary_json(\"lecture4.pdf\", location_tag=\"s3://my-bucket/example.pdf\")\n",
    "    print(json.dumps(summary, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "21316a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "import openai\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# ----------- JSON schema for guard‑railed output ----------------------------\n",
    "class SummaryJson(TypedDict):\n",
    "    content: str\n",
    "    title: str\n",
    "    description: str\n",
    "    location: str\n",
    "\n",
    "# ----------- Helper function to get embeddings ----------------------------\n",
    "def get_embeddings(text: str, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Gets the embeddings for the provided text using OpenAI's embeddings API.\n",
    "    \"\"\"\n",
    "    response = openai.embeddings.create(\n",
    "        model=model,\n",
    "        input=[text]  # The input should be a list of texts\n",
    "    )\n",
    "    embeddings = [embedding['embedding'] for embedding in response['data']]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# ----------- main callable --------------------------------------------------\n",
    "def pdf_to_summary_json(pdf_file: BytesIO, model_name: str = \"gpt-4\") -> SummaryJson:\n",
    "    \"\"\"\n",
    "    Extracts text from `pdf_file`, processes it, and returns mock test questions in SummaryJson format.\n",
    "    \"\"\"\n",
    "    # 1) Load & chunk the PDF content using PyPDFLoader and RecursiveCharacterTextSplitter\n",
    "    pdf_path = Path(\"uploaded_pdf.pdf\")\n",
    "    with open(pdf_path, \"wb\") as f:\n",
    "        f.write(pdf_file.read())\n",
    "\n",
    "    pages = PyPDFLoader(str(pdf_path)).load()\n",
    "\n",
    "    # Use RecursiveCharacterTextSplitter to break the document into chunks\n",
    "    chunks = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1_000, chunk_overlap=150\n",
    "    ).split_documents(pages)\n",
    "\n",
    "    # 2) Embed & store chunks in RAM\n",
    "    vectordb = InMemoryVectorStore(OpenAIEmbeddings())\n",
    "    vectordb.add_documents(chunks)\n",
    "\n",
    "    # 3) Retrieve top‑k context based on a query\n",
    "    question = \"Make a test for students based on the lecture material\"\n",
    "    docs = vectordb.similarity_search(question, k=6)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "    # 4) Generate JSON with structured output using GPT\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=0)\n",
    "    structured_llm = llm.with_structured_output(SummaryJson)  # forces valid schema\n",
    "\n",
    "    prompt = (\n",
    "        f\"\"\"You are a mock quiz generator. Based on the provided lecture notes, create the following types of questions:\n",
    "    - One answer with 4 options to pick.\n",
    "    - Multiple choice with 5-6 options to pick.\n",
    "    - Matching questions.\n",
    "\n",
    "    The provided lecture content: {context}\n",
    "\n",
    "    Output the result in the following JSON format:\n",
    "    [\n",
    "      {{\n",
    "        \"title\": \"Who was the first president of the United States?\",  // One choice question\n",
    "        \"variants\": [\n",
    "          \"George Washington\",  // Option 1\n",
    "          \"Abraham Lincoln\"  // Option 2\n",
    "        ],\n",
    "        \"correctVariantIndex\": 0  // Correct answer is the first option (index 0)\n",
    "      }},\n",
    "      {{\"title\": \"Which of the following countries were part of the Allied Powers in World War II?\", \n",
    "        \"variants\": [\n",
    "          \"United States\", \"Germany\", \"Soviet Union\", \"Italy\"\n",
    "        ],\n",
    "        \"correctVariantIndex\": [0, 2]\n",
    "      }},\n",
    "      {{\n",
    "        \"title\": \"Match the famous historical figures to their corresponding country:\", \n",
    "        \"variants\": [\n",
    "          \"George Washington\", \"Albert Einstein\", \"Winston Churchill\", \"Mahatma Gandhi\"\n",
    "        ],\n",
    "        \"correctVariantIndex\": [0, 1, 2, 3],\n",
    "        \"matchWith\": [\n",
    "          \"United States\", \"Germany\", \"United Kingdom\", \"India\"\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "\n",
    "    Ensure that the quiz questions are based only on the provided lecture notes or the test will fail.\"\"\"\n",
    "    )\n",
    "\n",
    "    json_out = structured_llm.invoke(prompt)\n",
    "\n",
    "    return json_out\n",
    "\n",
    "\n",
    "# ----------- FastAPI setup --------------------------------------------------\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/generate-quiz/\")\n",
    "async def generate_quiz(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Endpoint to generate mock quiz questions from the uploaded PDF file.\n",
    "    \"\"\"\n",
    "    # Read the PDF file content\n",
    "    pdf_file = await file.read()\n",
    "    try:\n",
    "        # Process the PDF and generate the summary JSON\n",
    "        result = pdf_to_summary_json(BytesIO(pdf_file))\n",
    "        return json.dumps(result, indent=2, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "802a8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: python-multipart\n",
      "Successfully installed python-multipart-0.0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80a3372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"title\": \"What is the primary focus of the lecture titled 'Algorithm II'?\",\n",
      "      \"variants\": [\n",
      "        \"Data Structures\",\n",
      "        \"Dynamic Connectivity\",\n",
      "        \"Sorting Algorithms\",\n",
      "        \"Graph Theory\"\n",
      "      ],\n",
      "      \"correctVariantIndex\": 1\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Which of the following methods is used to connect two objects in the Dynamic-Connectivity Client?\",\n",
      "      \"variants\": [\n",
      "        \"connect()\",\n",
      "        \"union()\",\n",
      "        \"link()\",\n",
      "        \"merge()\",\n",
      "        \"join()\"\n",
      "      ],\n",
      "      \"correctVariantIndex\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Match the following terms with their definitions:\",\n",
      "      \"variants\": [\n",
      "        \"Quick-Union\",\n",
      "        \"Quick-Find\",\n",
      "        \"Dynamic Connectivity\",\n",
      "        \"Union-Find\"\n",
      "      ],\n",
      "      \"correctVariantIndex\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3\n",
      "      ],\n",
      "      \"matchWith\": [\n",
      "        \"A method to connect components using tree structures.\",\n",
      "        \"A method to find components using an array.\",\n",
      "        \"A system to manage connections between objects dynamically.\",\n",
      "        \"A data structure that supports union and find operations.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    summary = pdf_to_summary_json(\"lecture4.pdf\", location_tag=\"s3://my-bucket/example.pdf\")\n",
    "    print(json.dumps(summary, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af543a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (0.115.9)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (0.34.2)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from fastapi) (0.45.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from fastapi) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from fastapi) (4.13.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from starlette<0.46.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\i9-14900k-2\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cb58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
